{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f823291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 361\n",
      "0 55761\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-338901737b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Row index range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_h\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Column index range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img_number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_h\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_w\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_w\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Columns and lists are not 0 The index of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# print(l)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "start_h, end_h, start_w, end_w = 0, 0, 0, 0 # The height and width of the character area start and end \n",
    "image = cv2.imread('C:/Users/ratne/Downloads/demo.jpg', 0) # Read directly as a grayscale image \n",
    "cv2.imshow('img_GRAY', image)\n",
    "_, image = cv2.threshold(image, 50, 255, cv2.THRESH_BINARY) # Two valued \n",
    "cv2.imshow('img_BINARY', image)\n",
    "# Get rid of the noise \n",
    "kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7)) # Simple corrosion expansion core \n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) # Simple corrosion expansion core \n",
    "image = cv2.erode(image, kernel=kernel1) # corrosion \n",
    "image = cv2.dilate(image, kernel=kernel2) # inflation \n",
    "cv2.imshow('img_denoise', image)\n",
    "h, w = image.shape # The height and width of the original \n",
    "# print(h, w)\"C:\\Users\\ratne\\Downloads\\allloha.jpg\"\n",
    "list1 = [] # Column sum \n",
    "list2 = [] # Row sum \n",
    "for i in range(w):\n",
    "    list1.append(1 if image[:, i].sum() != 0 else 0) # Summation , Not for 0 Set up 1\n",
    "    for i in range(h):\n",
    "        list2.append(1 if image[i, :].sum() != 0 else 0) # To sum up , Not for 0 Set up 1\n",
    "# print(len(list1))\n",
    "# print(len(list2))\n",
    "# Crop character region \n",
    "# Find the range of lines \n",
    "flag = 0\n",
    "for i, e in enumerate(list1):\n",
    "    if e != 0:\n",
    "        if flag == 0:\n",
    "            # The first one is not for 0 Location record of \n",
    "            start_w = i\n",
    "            flag = 1\n",
    "        else:\n",
    "            # The last one is not 0 The location of \n",
    "            end_w = i\n",
    "            # Find the range of columns \n",
    "            flag = 0\n",
    "for i, e in enumerate(list2):\n",
    "    if e != 0:\n",
    "        if flag == 0:\n",
    "            # The first one is not for 0 Location record of \n",
    "            start_h = i\n",
    "            flag = 1\n",
    "        else:\n",
    "            # The last one is not 0 The location of \n",
    "            end_h = i\n",
    "print(start_w, end_w) # Row index range \n",
    "print(start_h, end_h) # Column index range \n",
    "cv2.imshow('img_number', image[start_h:end_h, start_w:end_w])\n",
    "l = ([i for i, e in enumerate(list1) if e != 0]) # Columns and lists are not 0 The index of \n",
    "# print(l)\n",
    "img_list = [] # Split digital picture storage list \n",
    "temp = [] # Store all row index values of a number \n",
    "n = 0 # Number of digital pictures \n",
    "for x in l:\n",
    "    temp.append(x)\n",
    "    if x+1 not in l:\n",
    "        # Index discontinuities \n",
    "        if len(temp) != 1:\n",
    "            start_w = min(temp) # Index min \n",
    "            end_w = max(temp) # Index max \n",
    "            img_list.append(image[start_h:end_h, start_w:end_w]) # The index includes a number slice \n",
    "            n += 1\n",
    "# print(temp)\n",
    "temp = []\n",
    "print(n) # Number of characters \n",
    "for i in range(n):\n",
    "    # Display saved characters \n",
    "    cv2.imshow('number'+str(i), img_list[i])\n",
    "    cv2.imwrite('C:/Users/ratne/Downloads//demo'+str(i+1).zfill(2)+'.jpg', img_list[i])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68d0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#image = cv2.imread('C:/Users/ratne/Downloads/allloha.jpg') # Read directly as a grayscale image \n",
    "#cv2.imshow('img_GRAY', image)\n",
    "image = cv2.imread('C:/Users/ratne/Downloads/demo.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('hey',gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf68c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-16cf70050fa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hello'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import functools\n",
    " \n",
    "# Construct the argument parser and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-i\", \"C:/Users/ratne/Downloads/demo.jpg\", required=True, help=\"Path to the image\")\n",
    "#ap.add_argument(\"-m\", \"C:/Users/ratne/Downloads/model_hand.h5\", required=True, help=\"Path to the pre-trained model\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "###############################################\n",
    "# This takes two stages\n",
    "# The first stage is to segment characters\n",
    "# The second stage is to recognise characters\n",
    "###############################################\n",
    "\n",
    "###############################################\n",
    "# The first stage\n",
    "###############################################\n",
    "\n",
    "# Read the image and convert to grayscale\n",
    "image = cv2.imread('C:/Users/ratne/Downloads/demo.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the original image\n",
    "cv2.imshow(\"License Plate\", image)\n",
    "\n",
    "# Apply Gaussian blurring and thresholding \n",
    "# to reveal the characters on the license plate\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "\tcv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 45, 15)\n",
    "\n",
    "# Perform connected components analysis on the thresholded images and\n",
    "# initialize the mask to hold only the components we are interested in\n",
    "_, labels = cv2.connectedComponents(thresh)\n",
    "mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "\n",
    "# Set lower bound and upper bound criteria for characters\n",
    "total_pixels = image.shape[0] * image.shape[1]\n",
    "lower = total_pixels // 70 # heuristic param, can be fine tuned if necessary\n",
    "upper = total_pixels // 20 # heuristic param, can be fine tuned if necessary\n",
    "\n",
    "# Loop over the unique components\n",
    "for (i, label) in enumerate(np.unique(labels)):\n",
    "\t# If this is the background label, ignore it\n",
    "\tif label == 0:\n",
    "\t\tcontinue\n",
    " \n",
    "\t# Otherwise, construct the label mask to display only connected component\n",
    "\t# for the current label\n",
    "\tlabelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "\tlabelMask[labels == label] = 255\n",
    "\tnumPixels = cv2.countNonZero(labelMask)\n",
    " \n",
    "\t# If the number of pixels in the component is between lower bound and upper bound, \n",
    "\t# add it to our mask\n",
    "\tif numPixels > lower and numPixels < upper:\n",
    "\t\tmask = cv2.add(mask, labelMask)\n",
    "\n",
    "# Find contours and get bounding box for each contour\n",
    "cnts, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "\n",
    "# Sort the bounding boxes from left to right, top to bottom\n",
    "# sort by Y first, and then sort by X if Ys are similar\n",
    "def compare(rect1, rect2):\n",
    "    if abs(rect1[1] - rect2[1]) > 10:\n",
    "        return rect1[1] - rect2[1]\n",
    "    else:\n",
    "        return rect1[0] - rect2[0]\n",
    "boundingBoxes = sorted(boundingBoxes, key=functools.cmp_to_key(compare) )\n",
    "\n",
    "\n",
    "cv2.rectangle(image, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('hello',image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069371d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
